diff -NurpX linux-4.9.24-pax/Documentation/dontdiff linux-4.9.24/arch/x86/include/asm/boot.h linux-4.9.24-pax/arch/x86/include/asm/boot.h
--- linux-4.9.24/arch/x86/include/asm/boot.h	2016-07-25 02:13:19.043774793 +0200
+++ linux-4.9.24-pax/arch/x86/include/asm/boot.h	2017-01-01 22:57:10.625520784 +0100
@@ -6,7 +6,7 @@
 #include <uapi/asm/boot.h>
 
 /* Physical address where kernel should be loaded. */
-#define LOAD_PHYSICAL_ADDR ((CONFIG_PHYSICAL_START \
+#define ____LOAD_PHYSICAL_ADDR ((CONFIG_PHYSICAL_START \
 				+ (CONFIG_PHYSICAL_ALIGN - 1)) \
 				& ~(CONFIG_PHYSICAL_ALIGN - 1))
 
diff -NurpX linux-4.9.24-pax/Documentation/dontdiff linux-4.9.24/arch/x86/include/asm/pgtable_32_types.h linux-4.9.24-pax/arch/x86/include/asm/pgtable_32_types.h
--- linux-4.9.24/arch/x86/include/asm/pgtable_32_types.h	2015-03-18 15:21:50.244349253 +0100
+++ linux-4.9.24-pax/arch/x86/include/asm/pgtable_32_types.h	2017-01-01 22:57:10.633520804 +0100
@@ -46,6 +46,28 @@ extern bool __vmalloc_start_set; /* set
 # define VMALLOC_END	(FIXADDR_START - 2 * PAGE_SIZE)
 #endif
 
+#ifdef CONFIG_PAX_KERNEXEC
+#ifndef __ASSEMBLY__
+extern unsigned char MODULES_EXEC_VADDR[];
+extern unsigned char MODULES_EXEC_END[];
+
+extern unsigned char __LOAD_PHYSICAL_ADDR[];
+#define LOAD_PHYSICAL_ADDR ((unsigned long)__LOAD_PHYSICAL_ADDR)
+static inline unsigned long __intentional_overflow(-1) ktla_ktva(unsigned long addr)
+{
+	return addr + LOAD_PHYSICAL_ADDR + PAGE_OFFSET;
+
+}
+static inline unsigned long __intentional_overflow(-1) ktva_ktla(unsigned long addr)
+{
+	return addr - LOAD_PHYSICAL_ADDR - PAGE_OFFSET;
+}
+#endif
+#else
+#define ktla_ktva(addr)		(addr)
+#define ktva_ktla(addr)		(addr)
+#endif
+
 #define MODULES_VADDR	VMALLOC_START
 #define MODULES_END	VMALLOC_END
 #define MODULES_LEN	(MODULES_VADDR - MODULES_END)
diff -NurpX linux-4.9.24-pax/Documentation/dontdiff linux-4.9.24/arch/x86/boot/compressed/head_32.S linux-4.9.24-pax/arch/x86/boot/compressed/head_32.S
--- linux-4.9.24/arch/x86/boot/compressed/head_32.S	2016-12-13 12:08:26.242372959 +0100
+++ linux-4.9.24-pax/arch/x86/boot/compressed/head_32.S	2017-01-01 22:57:10.597520716 +0100
@@ -169,10 +169,10 @@ preferred_addr:
 	addl    %eax, %ebx
 	notl	%eax
 	andl    %eax, %ebx
-	cmpl	$LOAD_PHYSICAL_ADDR, %ebx
+	cmpl	$____LOAD_PHYSICAL_ADDR, %ebx
 	jge	1f
 #endif
-	movl	$LOAD_PHYSICAL_ADDR, %ebx
+	movl	$____LOAD_PHYSICAL_ADDR, %ebx
 1:
 
 	/* Target address to relocate to for decompression */
diff -NurpX linux-4.9.24-pax/Documentation/dontdiff linux-4.9.24/arch/x86/boot/compressed/head_64.S linux-4.9.24-pax/arch/x86/boot/compressed/head_64.S
--- linux-4.9.24/arch/x86/boot/compressed/head_64.S	2016-12-13 12:08:26.242372959 +0100
+++ linux-4.9.24-pax/arch/x86/boot/compressed/head_64.S	2017-02-12 20:54:55.289308383 +0100
@@ -103,10 +103,10 @@ ENTRY(startup_32)
 	addl	%eax, %ebx
 	notl	%eax
 	andl	%eax, %ebx
-	cmpl	$LOAD_PHYSICAL_ADDR, %ebx
+	cmpl	$____LOAD_PHYSICAL_ADDR, %ebx
 	jge	1f
 #endif
-	movl	$LOAD_PHYSICAL_ADDR, %ebx
+	movl	$____LOAD_PHYSICAL_ADDR, %ebx
 1:
 
 	/* Target address to relocate to for decompression */
@@ -333,10 +333,10 @@ preferred_addr:
 	addq	%rax, %rbp
 	notq	%rax
 	andq	%rax, %rbp
-	cmpq	$LOAD_PHYSICAL_ADDR, %rbp
+	cmpq	$____LOAD_PHYSICAL_ADDR, %rbp
 	jge	1f
 #endif
-	movq	$LOAD_PHYSICAL_ADDR, %rbp
+	movq	$____LOAD_PHYSICAL_ADDR, %rbp
 1:
 
 	/* Target address to relocate to for decompression */
diff -NurpX linux-4.9.24-pax/Documentation/dontdiff linux-4.9.24/arch/x86/boot/compressed/misc.c linux-4.9.24-pax/arch/x86/boot/compressed/misc.c
--- linux-4.9.24/arch/x86/boot/compressed/misc.c	2016-10-03 11:27:30.051075467 +0200
+++ linux-4.9.24-pax/arch/x86/boot/compressed/misc.c	2017-01-01 22:57:10.597520716 +0100
@@ -176,6 +176,10 @@ static void handle_relocations(void *out
 	int *reloc;
 	unsigned long delta, map, ptr;
 	unsigned long min_addr = (unsigned long)output;
+#if defined(CONFIG_X86_32) && defined(CONFIG_PAX_KERNEXEC)
+	unsigned long max_addr = min_addr + (VO___bss_start - VO__text - __PAGE_OFFSET - ____LOAD_PHYSICAL_ADDR);
+#else
 	unsigned long max_addr = min_addr + (VO___bss_start - VO__text);
+#endif
 
 	/*
@@ -182,7 +182,7 @@ static void handle_relocations(void *out
 	 * Calculate the delta between where vmlinux was linked to load
 	 * and where it was actually loaded.
 	 */
-	delta = min_addr - LOAD_PHYSICAL_ADDR;
+	delta = min_addr - ____LOAD_PHYSICAL_ADDR;
 
 	/*
 	 * The kernel contains a table of relocation addresses. Those
@@ -199,7 +199,7 @@ static void handle_relocations(void *out
 	 * from __START_KERNEL_map.
 	 */
 	if (IS_ENABLED(CONFIG_X86_64))
-		delta = virt_addr - LOAD_PHYSICAL_ADDR;
+		delta = virt_addr - ____LOAD_PHYSICAL_ADDR;
 
 	if (!delta) {
 		debug_putstr("No relocation needed... ");
@@ -301,7 +301,7 @@ static void parse_elf(void *output)
 		case PT_LOAD:
 #ifdef CONFIG_RELOCATABLE
 			dest = output;
-			dest += (phdr->p_paddr - LOAD_PHYSICAL_ADDR);
+			dest += (phdr->p_paddr - ____LOAD_PHYSICAL_ADDR);
 #else
 			dest = (void *)(phdr->p_paddr);
 #endif
@@ -337,7 +344,11 @@ asmlinkage __visible void *extract_kerne
 				  unsigned char *output,
 				  unsigned long output_len)
 {
+#if defined(CONFIG_X86_32) && defined(CONFIG_PAX_KERNEXEC)
+	const unsigned long kernel_total_size = VO__end - VO__text - __PAGE_OFFSET - ____LOAD_PHYSICAL_ADDR;
+#else
 	const unsigned long kernel_total_size = VO__end - VO__text;
+#endif
 	unsigned long virt_addr = (unsigned long)output;
 
 	/* Retain x86 boot parameters pointer passed from startup_32/64. */
@@ -395,7 +406,7 @@ asmlinkage __visible void *extract_kerne
 		error("Destination address too large");
 #endif
 #ifndef CONFIG_RELOCATABLE
-	if ((unsigned long)output != LOAD_PHYSICAL_ADDR)
+	if ((unsigned long)output != ____LOAD_PHYSICAL_ADDR)
 		error("Destination address does not match LOAD_PHYSICAL_ADDR");
 	if ((unsigned long)output != virt_addr)
 		error("Destination virtual address changed when not relocatable");
diff -NurpX linux-4.9.24-pax/Documentation/dontdiff linux-4.9.24/arch/x86/boot/header.S linux-4.9.24-pax/arch/x86/boot/header.S
--- linux-4.9.24/arch/x86/boot/header.S	2016-07-25 02:13:18.987734747 +0200
+++ linux-4.9.24-pax/arch/x86/boot/header.S	2017-01-01 22:57:10.597520716 +0100
@@ -438,7 +438,7 @@ setup_data:		.quad 0			# 64-bit physical
 						# single linked list of
 						# struct setup_data
 
-pref_address:		.quad LOAD_PHYSICAL_ADDR	# preferred load addr
+pref_address:		.quad ____LOAD_PHYSICAL_ADDR	# preferred load addr
 
 #
 # Getting to provably safe in-place decompression is hard. Worst case
@@ -543,7 +543,12 @@ pref_address:		.quad LOAD_PHYSICAL_ADDR
 
 #define ZO_INIT_SIZE	(ZO__end - ZO_startup_32 + ZO_z_min_extract_offset)
 
+#if defined(CONFIG_X86_32) && defined(CONFIG_PAX_KERNEXEC)
+#define VO_INIT_SIZE	(VO__end - VO__text - __PAGE_OFFSET - ____LOAD_PHYSICAL_ADDR)
+#else
 #define VO_INIT_SIZE	(VO__end - VO__text)
+#endif
+
 #if ZO_INIT_SIZE > VO_INIT_SIZE
 # define INIT_SIZE ZO_INIT_SIZE
 #else
diff -NurpX linux-4.9.24-pax/Documentation/dontdiff linux-4.9.24/arch/x86/kernel/alternative.c linux-4.9.24-pax/arch/x86/kernel/alternative.c
--- linux-4.9.24/arch/x86/kernel/alternative.c	2016-07-25 02:13:19.135839649 +0200
+++ linux-4.9.24-pax/arch/x86/kernel/alternative.c	2017-01-30 00:37:12.088733010 +0100
@@ -21,6 +21,7 @@
 #include <asm/tlbflush.h>
 #include <asm/io.h>
 #include <asm/fixmap.h>
+#include <asm/boot.h>
 
 int __read_mostly alternatives_patched;
 
@@ -290,6 +293,13 @@ recompute_jump(struct alt_instr *a, u8 *
 	if (a->replacementlen != 5)
 		return;
 
+#if defined(CONFIG_X86_32) && defined(CONFIG_PAX_KERNEXEC)
+	if (orig_insn < (u8 *)_text || (u8 *)_einittext <= orig_insn)
+		orig_insn = (u8 *)ktva_ktla((unsigned long)orig_insn);
+	else
+		orig_insn -= ____LOAD_PHYSICAL_ADDR - LOAD_PHYSICAL_ADDR;
+#endif
+
 	o_dspl = *(s32 *)(insnbuf + 1);
 
 	/* next_rip of the replacement JMP */
@@ -365,6 +375,7 @@ void __init_or_module apply_alternatives
 {
 	struct alt_instr *a;
 	u8 *instr, *replacement;
+	u8 *vinstr, *vreplacement;
 	u8 insnbuf[MAX_PATCH_LEN];
 
 	DPRINTK("alt table %p -> %p", start, end);
@@ -380,46 +391,71 @@ void __init_or_module apply_alternatives
 	for (a = start; a < end; a++) {
 		int insnbuf_sz = 0;
 
-		instr = (u8 *)&a->instr_offset + a->instr_offset;
-		replacement = (u8 *)&a->repl_offset + a->repl_offset;
+		vinstr = instr = (u8 *)&a->instr_offset + a->instr_offset;
+
+#if defined(CONFIG_X86_32) && defined(CONFIG_PAX_KERNEXEC)
+		if ((u8 *)_text - (____LOAD_PHYSICAL_ADDR - LOAD_PHYSICAL_ADDR) <= instr &&
+		    instr < (u8 *)_einittext - (____LOAD_PHYSICAL_ADDR - LOAD_PHYSICAL_ADDR)) {
+			instr += ____LOAD_PHYSICAL_ADDR - LOAD_PHYSICAL_ADDR;
+			vinstr = (u8 *)ktla_ktva((unsigned long)instr);
+		} else if ((u8 *)_text <= instr && instr < (u8 *)_einittext) {
+			vinstr = (u8 *)ktla_ktva((unsigned long)instr);
+		} else {
+			instr = (u8 *)ktva_ktla((unsigned long)instr);
+		}
+#endif
+
+		vreplacement = replacement = (u8 *)&a->repl_offset + a->repl_offset;
+
+#if defined(CONFIG_X86_32) && defined(CONFIG_PAX_KERNEXEC)
+		if ((u8 *)_text - (____LOAD_PHYSICAL_ADDR - LOAD_PHYSICAL_ADDR) <= replacement &&
+		    replacement < (u8 *)_einittext - (____LOAD_PHYSICAL_ADDR - LOAD_PHYSICAL_ADDR)) {
+			replacement += ____LOAD_PHYSICAL_ADDR - LOAD_PHYSICAL_ADDR;
+			vreplacement = (u8 *)ktla_ktva((unsigned long)replacement);
+		} else if ((u8 *)_text <= replacement && replacement < (u8 *)_einittext) {
+			vreplacement = (u8 *)ktla_ktva((unsigned long)replacement);
+		} else
+			replacement = (u8 *)ktva_ktla((unsigned long)replacement);
+#endif
+
 		BUG_ON(a->instrlen > sizeof(insnbuf));
 		BUG_ON(a->cpuid >= (NCAPINTS + NBUGINTS) * 32);
 		if (!boot_cpu_has(a->cpuid)) {
 			if (a->padlen > 1)
-				optimize_nops(a, instr);
+				optimize_nops(a, vinstr);
 
 			continue;
 		}
 
-		DPRINTK("feat: %d*32+%d, old: (%p, len: %d), repl: (%p, len: %d), pad: %d",
+		DPRINTK("feat: %d*32+%d, old: (%p/%p, len: %d), repl: (%p, len: %d), pad: %d",
 			a->cpuid >> 5,
 			a->cpuid & 0x1f,
-			instr, a->instrlen,
-			replacement, a->replacementlen, a->padlen);
+			instr, vinstr, a->instrlen,
+			vreplacement, a->replacementlen, a->padlen);
 
-		DUMP_BYTES(instr, a->instrlen, "%p: old_insn: ", instr);
-		DUMP_BYTES(replacement, a->replacementlen, "%p: rpl_insn: ", replacement);
+		DUMP_BYTES(vinstr, a->instrlen, "%p: old_insn: ", vinstr);
+		DUMP_BYTES(vreplacement, a->replacementlen, "%p: rpl_insn: ", vreplacement);
 
-		memcpy(insnbuf, replacement, a->replacementlen);
+		memcpy(insnbuf, vreplacement, a->replacementlen);
 		insnbuf_sz = a->replacementlen;
 
-		/* 0xe8 is a relative jump; fix the offset. */
+		/* 0xe8 is a call; fix the relative offset. */
 		if (*insnbuf == 0xe8 && a->replacementlen == 5) {
-			*(s32 *)(insnbuf + 1) += replacement - instr;
+			*(s32 *)(insnbuf + 1) += vreplacement - instr;
 			DPRINTK("Fix CALL offset: 0x%x, CALL 0x%lx",
 				*(s32 *)(insnbuf + 1),
-				(unsigned long)instr + *(s32 *)(insnbuf + 1) + 5);
+				(unsigned long)vinstr + *(s32 *)(insnbuf + 1) + 5);
 		}
 
-		if (a->replacementlen && is_jmp(replacement[0]))
-			recompute_jump(a, instr, replacement, insnbuf);
+		if (a->replacementlen && is_jmp(vreplacement[0]))
+			recompute_jump(a, instr, vreplacement, insnbuf);
 
 		if (a->instrlen > a->replacementlen) {
 			add_nops(insnbuf + a->replacementlen,
 				 a->instrlen - a->replacementlen);
 			insnbuf_sz += a->instrlen - a->replacementlen;
 		}
-		DUMP_BYTES(insnbuf, insnbuf_sz, "%p: final_insn: ", instr);
+		DUMP_BYTES(insnbuf, insnbuf_sz, "%p: final_insn: ", vinstr);
 
 		text_poke_early(instr, insnbuf, insnbuf_sz);
 	}
@@ -435,10 +481,16 @@ static void alternatives_smp_lock(const
 	for (poff = start; poff < end; poff++) {
 		u8 *ptr = (u8 *)poff + *poff;
 
+#if defined(CONFIG_X86_32) && defined(CONFIG_PAX_KERNEXEC)
+		ptr += ____LOAD_PHYSICAL_ADDR - LOAD_PHYSICAL_ADDR;
+		if (ptr < (u8 *)_text || (u8 *)_einittext <= ptr)
+			ptr -= ____LOAD_PHYSICAL_ADDR - LOAD_PHYSICAL_ADDR;
+#endif
+
 		if (!*poff || ptr < text || ptr >= text_end)
 			continue;
 		/* turn DS segment override prefix into lock prefix */
-		if (*ptr == 0x3e)
+		if (*(u8 *)ktla_ktva((unsigned long)ptr) == 0x3e)
 			text_poke(ptr, ((unsigned char []){0xf0}), 1);
 	}
 	mutex_unlock(&text_mutex);
@@ -453,10 +505,16 @@ static void alternatives_smp_unlock(cons
 	for (poff = start; poff < end; poff++) {
 		u8 *ptr = (u8 *)poff + *poff;
 
+#if defined(CONFIG_X86_32) && defined(CONFIG_PAX_KERNEXEC)
+		ptr += ____LOAD_PHYSICAL_ADDR - LOAD_PHYSICAL_ADDR;
+		if (ptr < (u8 *)_text || (u8 *)_einittext <= ptr)
+			ptr -= ____LOAD_PHYSICAL_ADDR - LOAD_PHYSICAL_ADDR;
+#endif
+
 		if (!*poff || ptr < text || ptr >= text_end)
 			continue;
 		/* turn lock prefix into DS segment override prefix */
-		if (*ptr == 0xf0)
+		if (*(u8 *)ktla_ktva((unsigned long)ptr) == 0xf0)
 			text_poke(ptr, ((unsigned char []){0x3E}), 1);
 	}
 	mutex_unlock(&text_mutex);
@@ -593,7 +653,7 @@ void __init_or_module apply_paravirt(str
 
 		BUG_ON(p->len > MAX_PATCH_LEN);
 		/* prep the buffer with the original instructions */
-		memcpy(insnbuf, p->instr, p->len);
+		memcpy(insnbuf, (const void *)ktla_ktva((unsigned long)p->instr), p->len);
 		used = pv_init_ops.patch(p->instrtype, p->clobbers, insnbuf,
 					 (unsigned long)p->instr, p->len);
 
@@ -661,13 +721,17 @@ void __init alternative_instructions(voi
  * instructions. And on the local CPU you need to be protected again NMI or MCE
  * handlers seeing an inconsistent instruction while you patch.
  */
-void *__init_or_module text_poke_early(void *addr, const void *opcode,
+void *__kprobes text_poke_early(void *addr, const void *opcode,
 					      size_t len)
 {
 	unsigned long flags;
 	local_irq_save(flags);
-	memcpy(addr, opcode, len);
+
+	pax_open_kernel();
+	memcpy((void *)ktla_ktva((unsigned long)addr), opcode, len);
 	sync_core();
+	pax_close_kernel();
+
 	local_irq_restore(flags);
 	/* Could also do a CLFLUSH here to speed up CPU recovery; but
 	   that causes hangs on some VIA CPUs. */
@@ -689,20 +753,29 @@ void *__init_or_module text_poke_early(v
  */
 void *text_poke(void *addr, const void *opcode, size_t len)
 {
-	unsigned long flags;
-	char *vaddr;
+	unsigned char *vaddr = (void *)ktla_ktva((unsigned long)addr);
 	struct page *pages[2];
-	int i;
+	size_t i;
+
+#ifndef CONFIG_PAX_KERNEXEC
+	unsigned long flags;
+#endif
 
 	if (!core_kernel_text((unsigned long)addr)) {
-		pages[0] = vmalloc_to_page(addr);
-		pages[1] = vmalloc_to_page(addr + PAGE_SIZE);
+		pages[0] = vmalloc_to_page(vaddr);
+		pages[1] = vmalloc_to_page(vaddr + PAGE_SIZE);
 	} else {
-		pages[0] = virt_to_page(addr);
+		pages[0] = virt_to_page(vaddr);
 		WARN_ON(!PageReserved(pages[0]));
-		pages[1] = virt_to_page(addr + PAGE_SIZE);
+		pages[1] = virt_to_page(vaddr + PAGE_SIZE);
 	}
 	BUG_ON(!pages[0]);
+
+#ifdef CONFIG_PAX_KERNEXEC
+	text_poke_early(addr, opcode, len);
+	for (i = 0; i < len; i++)
+		BUG_ON((vaddr)[i] != ((const unsigned char *)opcode)[i]);
+#else
 	local_irq_save(flags);
 	set_fixmap(FIX_TEXT_POKE0, page_to_phys(pages[0]));
 	if (pages[1])
@@ -719,6 +792,7 @@ void *text_poke(void *addr, const void *
 	for (i = 0; i < len; i++)
 		BUG_ON(((char *)addr)[i] != ((char *)opcode)[i]);
 	local_irq_restore(flags);
+#endif
 	return addr;
 }
 
diff -NurpX linux-4.9.24-pax/Documentation/dontdiff linux-4.9.24/arch/x86/realmode/init.c linux-4.9.24-pax/arch/x86/realmode/init.c
--- linux-4.9.24/arch/x86/realmode/init.c	2016-10-03 11:27:32.142621638 +0200
+++ linux-4.9.24-pax/arch/x86/realmode/init.c	2017-01-01 22:57:10.705520981 +0100
@@ -85,7 +85,13 @@ static void __init setup_real_mode(void)
 		__va(real_mode_header->trampoline_header);
 
 #ifdef CONFIG_X86_32
-	trampoline_header->start = __pa_symbol(startup_32_smp);
+	trampoline_header->start = __pa_symbol(ktla_ktva((unsigned long)startup_32_smp));
+
+#ifdef CONFIG_PAX_KERNEXEC
+	trampoline_header->start -= LOAD_PHYSICAL_ADDR;
+#endif
+
+	trampoline_header->boot_cs = __BOOT_CS;
 	trampoline_header->gdt_limit = __BOOT_DS + 7;
 	trampoline_header->gdt_base = __pa_symbol(boot_gdt);
 #else
