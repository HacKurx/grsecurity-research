diff -NurpX linux-4.9.24-pax/Documentation/dontdiff linux-4.9.24/arch/arm/crypto/sha1_glue.c linux-4.9.24-pax/arch/arm/crypto/sha1_glue.c
--- linux-4.9.24/arch/arm/crypto/sha1_glue.c	2015-06-22 11:14:08.548675290 +0200
+++ linux-4.9.24-pax/arch/arm/crypto/sha1_glue.c	2017-01-01 22:57:10.517520519 +0100
@@ -27,8 +27,8 @@
 
 #include "sha1.h"
 
-asmlinkage void sha1_block_data_order(u32 *digest,
-		const unsigned char *data, unsigned int rounds);
+asmlinkage void sha1_block_data_order(struct sha1_state *digest,
+		const u8 *data, int rounds);
 
 int sha1_update_arm(struct shash_desc *desc, const u8 *data,
 		    unsigned int len)
@@ -36,22 +36,20 @@ int sha1_update_arm(struct shash_desc *d
 	/* make sure casting to sha1_block_fn() is safe */
 	BUILD_BUG_ON(offsetof(struct sha1_state, state) != 0);
 
-	return sha1_base_do_update(desc, data, len,
-				   (sha1_block_fn *)sha1_block_data_order);
+	return sha1_base_do_update(desc, data, len, sha1_block_data_order);
 }
 EXPORT_SYMBOL_GPL(sha1_update_arm);
 
 static int sha1_final(struct shash_desc *desc, u8 *out)
 {
-	sha1_base_do_finalize(desc, (sha1_block_fn *)sha1_block_data_order);
+	sha1_base_do_finalize(desc, sha1_block_data_order);
 	return sha1_base_finish(desc, out);
 }
 
 int sha1_finup_arm(struct shash_desc *desc, const u8 *data,
 		   unsigned int len, u8 *out)
 {
-	sha1_base_do_update(desc, data, len,
-			    (sha1_block_fn *)sha1_block_data_order);
+	sha1_base_do_update(desc, data, len, sha1_block_data_order);
 	return sha1_final(desc, out);
 }
 EXPORT_SYMBOL_GPL(sha1_finup_arm);
diff -NurpX linux-4.9.24-pax/Documentation/dontdiff linux-4.9.24/arch/arm/crypto/sha1_neon_glue.c linux-4.9.24-pax/arch/arm/crypto/sha1_neon_glue.c
--- linux-4.9.24/arch/arm/crypto/sha1_neon_glue.c	2015-06-22 11:14:08.548675290 +0200
+++ linux-4.9.24-pax/arch/arm/crypto/sha1_neon_glue.c	2017-01-01 22:57:10.517520519 +0100
@@ -31,8 +31,8 @@
 
 #include "sha1.h"
 
-asmlinkage void sha1_transform_neon(void *state_h, const char *data,
-				    unsigned int rounds);
+asmlinkage void sha1_transform_neon(struct sha1_state *state_h, const u8 *data,
+				    int rounds);
 
 static int sha1_neon_update(struct shash_desc *desc, const u8 *data,
 			  unsigned int len)
@@ -45,7 +45,7 @@ static int sha1_neon_update(struct shash
 
 	kernel_neon_begin();
 	sha1_base_do_update(desc, data, len,
-			    (sha1_block_fn *)sha1_transform_neon);
+			    sha1_transform_neon);
 	kernel_neon_end();
 
 	return 0;
@@ -60,8 +60,8 @@ static int sha1_neon_finup(struct shash_
 	kernel_neon_begin();
 	if (len)
 		sha1_base_do_update(desc, data, len,
-				    (sha1_block_fn *)sha1_transform_neon);
-	sha1_base_do_finalize(desc, (sha1_block_fn *)sha1_transform_neon);
+				    sha1_transform_neon);
+	sha1_base_do_finalize(desc, sha1_transform_neon);
 	kernel_neon_end();
 
 	return sha1_base_finish(desc, out);
diff -NurpX linux-4.9.24-pax/Documentation/dontdiff linux-4.9.24/arch/arm/crypto/sha256_glue.c linux-4.9.24-pax/arch/arm/crypto/sha256_glue.c
--- linux-4.9.24/arch/arm/crypto/sha256_glue.c	2015-06-22 11:14:08.552675290 +0200
+++ linux-4.9.24-pax/arch/arm/crypto/sha256_glue.c	2017-01-01 22:57:10.517520519 +0100
@@ -30,8 +30,8 @@
 
 #include "sha256_glue.h"
 
-asmlinkage void sha256_block_data_order(u32 *digest, const void *data,
-					unsigned int num_blks);
+asmlinkage void sha256_block_data_order(struct sha256_state *digest, const u8 *data,
+					int num_blks);
 
 int crypto_sha256_arm_update(struct shash_desc *desc, const u8 *data,
 			     unsigned int len)
@@ -39,23 +39,20 @@ int crypto_sha256_arm_update(struct shas
 	/* make sure casting to sha256_block_fn() is safe */
 	BUILD_BUG_ON(offsetof(struct sha256_state, state) != 0);
 
-	return sha256_base_do_update(desc, data, len,
-				(sha256_block_fn *)sha256_block_data_order);
+	return sha256_base_do_update(desc, data, len, sha256_block_data_order);
 }
 EXPORT_SYMBOL(crypto_sha256_arm_update);
 
 static int sha256_final(struct shash_desc *desc, u8 *out)
 {
-	sha256_base_do_finalize(desc,
-				(sha256_block_fn *)sha256_block_data_order);
+	sha256_base_do_finalize(desc, sha256_block_data_order);
 	return sha256_base_finish(desc, out);
 }
 
 int crypto_sha256_arm_finup(struct shash_desc *desc, const u8 *data,
 			    unsigned int len, u8 *out)
 {
-	sha256_base_do_update(desc, data, len,
-			      (sha256_block_fn *)sha256_block_data_order);
+	sha256_base_do_update(desc, data, len, sha256_block_data_order);
 	return sha256_final(desc, out);
 }
 EXPORT_SYMBOL(crypto_sha256_arm_finup);
diff -NurpX linux-4.9.24-pax/Documentation/dontdiff linux-4.9.24/arch/arm/crypto/sha256_neon_glue.c linux-4.9.24-pax/arch/arm/crypto/sha256_neon_glue.c
--- linux-4.9.24/arch/arm/crypto/sha256_neon_glue.c	2015-06-22 11:14:08.552675290 +0200
+++ linux-4.9.24-pax/arch/arm/crypto/sha256_neon_glue.c	2017-01-01 22:57:10.521520529 +0100
@@ -26,8 +26,8 @@
 
 #include "sha256_glue.h"
 
-asmlinkage void sha256_block_data_order_neon(u32 *digest, const void *data,
-					     unsigned int num_blks);
+asmlinkage void sha256_block_data_order_neon(struct sha256_state *digest, const u8 *data,
+					     int num_blks);
 
 static int sha256_update(struct shash_desc *desc, const u8 *data,
 			 unsigned int len)
@@ -39,8 +39,7 @@ static int sha256_update(struct shash_de
 		return crypto_sha256_arm_update(desc, data, len);
 
 	kernel_neon_begin();
-	sha256_base_do_update(desc, data, len,
-			(sha256_block_fn *)sha256_block_data_order_neon);
+	sha256_base_do_update(desc, data, len, sha256_block_data_order_neon);
 	kernel_neon_end();
 
 	return 0;
@@ -54,10 +53,8 @@ static int sha256_finup(struct shash_des
 
 	kernel_neon_begin();
 	if (len)
-		sha256_base_do_update(desc, data, len,
-			(sha256_block_fn *)sha256_block_data_order_neon);
-	sha256_base_do_finalize(desc,
-			(sha256_block_fn *)sha256_block_data_order_neon);
+		sha256_base_do_update(desc, data, len, sha256_block_data_order_neon);
+	sha256_base_do_finalize(desc, sha256_block_data_order_neon);
 	kernel_neon_end();
 
 	return sha256_base_finish(desc, out);
diff -NurpX linux-4.9.24-pax/Documentation/dontdiff linux-4.9.24/arch/arm/crypto/sha512-glue.c linux-4.9.24-pax/arch/arm/crypto/sha512-glue.c
--- linux-4.9.24/arch/arm/crypto/sha512-glue.c	2015-09-09 11:16:55.083258210 +0200
+++ linux-4.9.24-pax/arch/arm/crypto/sha512-glue.c	2017-01-01 22:57:10.521520529 +0100
@@ -28,27 +28,24 @@ MODULE_ALIAS_CRYPTO("sha512");
 MODULE_ALIAS_CRYPTO("sha384-arm");
 MODULE_ALIAS_CRYPTO("sha512-arm");
 
-asmlinkage void sha512_block_data_order(u64 *state, u8 const *src, int blocks);
+asmlinkage void sha512_block_data_order(struct sha512_state *state, u8 const *src, int blocks);
 
 int sha512_arm_update(struct shash_desc *desc, const u8 *data,
 		      unsigned int len)
 {
-	return sha512_base_do_update(desc, data, len,
-		(sha512_block_fn *)sha512_block_data_order);
+	return sha512_base_do_update(desc, data, len, sha512_block_data_order);
 }
 
 int sha512_arm_final(struct shash_desc *desc, u8 *out)
 {
-	sha512_base_do_finalize(desc,
-		(sha512_block_fn *)sha512_block_data_order);
+	sha512_base_do_finalize(desc, sha512_block_data_order);
 	return sha512_base_finish(desc, out);
 }
 
 int sha512_arm_finup(struct shash_desc *desc, const u8 *data,
 		     unsigned int len, u8 *out)
 {
-	sha512_base_do_update(desc, data, len,
-		(sha512_block_fn *)sha512_block_data_order);
+	sha512_base_do_update(desc, data, len, sha512_block_data_order);
 	return sha512_arm_final(desc, out);
 }
 
diff -NurpX linux-4.9.24-pax/Documentation/dontdiff linux-4.9.24/arch/arm/crypto/sha512-neon-glue.c linux-4.9.24-pax/arch/arm/crypto/sha512-neon-glue.c
--- linux-4.9.24/arch/arm/crypto/sha512-neon-glue.c	2015-09-09 11:16:55.083258210 +0200
+++ linux-4.9.24-pax/arch/arm/crypto/sha512-neon-glue.c	2017-01-01 22:57:10.521520529 +0100
@@ -22,7 +22,7 @@
 MODULE_ALIAS_CRYPTO("sha384-neon");
 MODULE_ALIAS_CRYPTO("sha512-neon");
 
-asmlinkage void sha512_block_data_order_neon(u64 *state, u8 const *src,
+asmlinkage void sha512_block_data_order_neon(struct sha512_state *state, u8 const *src,
 					     int blocks);
 
 static int sha512_neon_update(struct shash_desc *desc, const u8 *data,
@@ -35,8 +35,7 @@ static int sha512_neon_update(struct sha
 		return sha512_arm_update(desc, data, len);
 
 	kernel_neon_begin();
-	sha512_base_do_update(desc, data, len,
-		(sha512_block_fn *)sha512_block_data_order_neon);
+	sha512_base_do_update(desc, data, len, sha512_block_data_order_neon);
 	kernel_neon_end();
 
 	return 0;
@@ -50,10 +49,8 @@ static int sha512_neon_finup(struct shas
 
 	kernel_neon_begin();
 	if (len)
-		sha512_base_do_update(desc, data, len,
-			(sha512_block_fn *)sha512_block_data_order_neon);
-	sha512_base_do_finalize(desc,
-		(sha512_block_fn *)sha512_block_data_order_neon);
+		sha512_base_do_update(desc, data, len, sha512_block_data_order_neon);
+	sha512_base_do_finalize(desc, sha512_block_data_order_neon);
 	kernel_neon_end();
 
 	return sha512_base_finish(desc, out);
diff -NurpX linux-4.9.24-pax/Documentation/dontdiff linux-4.9.24/arch/arm64/crypto/sha1-ce-glue.c linux-4.9.24-pax/arch/arm64/crypto/sha1-ce-glue.c
--- linux-4.9.24/arch/arm64/crypto/sha1-ce-glue.c	2015-06-22 11:14:09.544675288 +0200
+++ linux-4.9.24-pax/arch/arm64/crypto/sha1-ce-glue.c	2017-01-01 22:57:10.549520598 +0100
@@ -29,7 +29,7 @@ struct sha1_ce_state {
 	u32			finalize;
 };
 
-asmlinkage void sha1_ce_transform(struct sha1_ce_state *sst, u8 const *src,
+asmlinkage void sha1_ce_transform(struct sha1_state *sst, u8 const *src,
 				  int blocks);
 
 static int sha1_ce_update(struct shash_desc *desc, const u8 *data,
@@ -39,8 +39,7 @@ static int sha1_ce_update(struct shash_d
 
 	sctx->finalize = 0;
 	kernel_neon_begin_partial(16);
-	sha1_base_do_update(desc, data, len,
-			    (sha1_block_fn *)sha1_ce_transform);
+	sha1_base_do_update(desc, data, len, sha1_ce_transform);
 	kernel_neon_end();
 
 	return 0;
@@ -64,10 +63,9 @@ static int sha1_ce_finup(struct shash_de
 	sctx->finalize = finalize;
 
 	kernel_neon_begin_partial(16);
-	sha1_base_do_update(desc, data, len,
-			    (sha1_block_fn *)sha1_ce_transform);
+	sha1_base_do_update(desc, data, len, sha1_ce_transform);
 	if (!finalize)
-		sha1_base_do_finalize(desc, (sha1_block_fn *)sha1_ce_transform);
+		sha1_base_do_finalize(desc, sha1_ce_transform);
 	kernel_neon_end();
 	return sha1_base_finish(desc, out);
 }
@@ -78,7 +76,7 @@ static int sha1_ce_final(struct shash_de
 
 	sctx->finalize = 0;
 	kernel_neon_begin_partial(16);
-	sha1_base_do_finalize(desc, (sha1_block_fn *)sha1_ce_transform);
+	sha1_base_do_finalize(desc, sha1_ce_transform);
 	kernel_neon_end();
 	return sha1_base_finish(desc, out);
 }
